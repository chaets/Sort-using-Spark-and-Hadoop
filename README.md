# Sort-using-Spark-and-Hadoop
This project covers sort through Hadoop and Spark on multiple nodes. We have used Linux system to implement your application and used the Proton Cluster accessible at 216.47.142.37; each Hadoop group (cluster) has 4 nodes, each node having 4-cores, 8GB of memory, and 80GB of SSD storage.
## Compile



########### Sorting ###########

<workload type (8, 20 and 80 GB)>

###### Compile #####

Run these files for Hadoop under /PA2b Folder
hadoopsort8GB.slurm
hadoopsort20GB.slurm
hadoopsort80GB.slurm

Run these files for Spark under /SPPA2 folder

sparksort8GB.slurm
sparksort20GB.slurm
sparksort80GB.slurm


########### Sorting ###########

these slurm files will run .sh files accocited with different size datasets
output will be given in the .log files in the respected folders.
